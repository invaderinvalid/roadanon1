# ğŸ›£ Real-Time Road Anomaly Detection on Raspberry Pi 4B

> **IIT Madras â€” Bharat AI System-on-Chip Challenge**
>
> Edge AI application that processes dashcam footage in real-time to detect and log road anomalies on a Raspberry Pi 4B.

[![Python](https://img.shields.io/badge/Python-3.11+-blue?logo=python&logoColor=white)](https://python.org)
[![Platform](https://img.shields.io/badge/Platform-Raspberry%20Pi%204B-c51a4a?logo=raspberrypi&logoColor=white)](https://www.raspberrypi.com)
[![License](https://img.shields.io/badge/License-MIT-green.svg)](LICENSE)

---

## ğŸ“‹ Table of Contents

- [Overview](#overview)
- [Architecture](#architecture)
- [Detection Classes](#detection-classes)
- [Hardware Setup](#hardware-setup)
- [Installation](#installation)
- [Quick Start](#quick-start)
- [GUI Application](#gui-application)
- [Pipeline Modes](#pipeline-modes)
- [Benchmarks](#benchmarks)
- [Optimization Techniques](#optimization-techniques)
- [Project Structure](#project-structure)
- [Configuration](#configuration)
- [Output Formats](#output-formats)
- [Team](#team)

---

## Overview

This project deploys a **dual-model AI pipeline** on a Raspberry Pi 4B that detects road anomalies from dashcam video in real-time. It combines a lightweight **convolutional autoencoder** (pre-filter) with **YOLOv26n** (detector) to achieve >10 FPS under severe hardware constraints.

### Key Features

- âš¡ **Real-time inference** on CPU-only hardware (no GPU required)
- ğŸ§  **Dual-model architecture**: Autoencoder pre-filter + YOLOv26n detector
- ğŸ”„ **Asynchronous YOLO**: Non-blocking inference on background thread
- ğŸ“Š **Rich HUD overlay**: AE error, YOLO status, latency, motion %
- ğŸ–¥ï¸ **Tkinter GUI**: Live video, AE visualization, anomaly alerts
- ğŸ“ **Structured logging**: Per-frame CSV + per-detection JSONL
- ğŸŒ¡ï¸ **Hardware benchmarking**: CPU, RAM, temperature monitoring
- ğŸ¯ **Motion-weighted thresholds**: Intelligent anomaly gating

---

## Architecture

### System Pipeline

```mermaid
flowchart TB
    subgraph Thread1["ğŸ¥ Thread 1 â€” Camera I/O"]
        A[Camera / Video Input] --> B[Frame Capture]
    end

    subgraph MainThread["âš™ï¸ Main Thread â€” Processing"]
        B --> C[Resize to 320Ã—240]
        C --> D[ROI Crop â€” Bottom 50%]
        D --> E[Motion Detection]
        E --> F{Motion Weight}
        F -->|"< 0.1%: noise"| G["w = 3.0 â€” skeptical"]
        F -->|"2-30%: sweet spot"| H["w = 1.0 â€” standard"]
        F -->|"> 50%: shake"| I["w = 1.8 â€” cautious"]
        G --> J[AE Pre-filter]
        H --> J
        I --> J
        J -->|"Anomaly confirmed"| K[Submit to YOLO Queue]
        J -->|"Normal road"| L[Skip YOLO]
    end

    subgraph Thread23["ğŸ§  Thread 2-3 â€” YOLO Inference"]
        K --> M[YOLOv26n NCNN]
        M --> N[Detections]
    end

    subgraph Output["ğŸ“Š Output"]
        N --> O[IoU Tracker]
        L --> O
        O --> P[CSV + JSONL Logs]
        O --> Q[Annotated Video]
        O --> R[GUI Display]
    end

    style Thread1 fill:#1a3a5c,stroke:#4a9eff,color:#fff
    style MainThread fill:#1a3a1a,stroke:#4aff4a,color:#fff
    style Thread23 fill:#3a1a3a,stroke:#ff4aff,color:#fff
    style Output fill:#3a3a1a,stroke:#ffff4a,color:#fff
```

### Decision Flow

```mermaid
flowchart LR
    A[Frame] --> B{Motion?}
    B -->|No| Z[Skip]
    B -->|Yes| C[Compute Weight]
    C --> D{All Tracked?}
    D -->|Yes| E{Recheck interval?}
    D -->|No| F[Run AE]
    E -->|Yes| F
    E -->|No| Z
    F --> G{AE Anomaly?}
    G -->|No| Z
    G -->|Yes| H{Cooldown = 0?}
    H -->|No| Z
    H -->|Yes| I[Submit YOLO]
    I --> J[Reset Cooldown = 5]
```

### Autoencoder Pipeline

```mermaid
flowchart LR
    A["ROI Frame\n(320Ã—120)"] --> B["Resize\n128Ã—128"]
    B --> C["Normalize\nÃ· 255.0"]
    C --> D["Cast to\nFP16"]
    D --> E["ONNX Runtime\nEncoder â†’ Decoder"]
    E --> F["Reconstruction\n128Ã—128"]
    C --> G["Error =\n|Input - Recon|"]
    F --> G
    G --> H["Mean Error"]
    H --> I{"error > Ï„ Ã— w\n2 of 5 frames?"}
    I -->|Yes| J["âš  Anomaly"]
    I -->|No| K["âœ“ Normal"]

    style J fill:#ff3333,color:#fff
    style K fill:#33cc33,color:#fff
```

---

## Detection Classes

| Class | Description | Color |
|-------|-------------|-------|
| ğŸ”´ `road_damage` | Potholes, cracks, surface degradation | Red |
| ğŸŸ  `speed_bump` | Unmarked or poorly visible speed bumps | Orange |
| ğŸŸ¡ `unsurfaced_road` | Transitions from paved to unpaved | Cyan |

---

## Hardware Setup

| Component | Specification |
|-----------|--------------|
| **Board** | Raspberry Pi 4 Model B |
| **CPU** | 4Ã— Cortex-A72 @ 1.5 GHz (ARMv8-A) |
| **RAM** | 4 GB LPDDR4-3200 |
| **Storage** | 32 GB microSD (Class 10) |
| **Cooling** | Aluminium heatsink + active fan |
| **Camera** | Raspberry Pi Camera Module (CSI) |
| **Power** | 5V / 3A USB-C |
| **OS** | Raspberry Pi OS (64-bit, Bookworm) |

---

## Installation

### Prerequisites

```bash
# Python 3.11+
python3 --version

# System dependencies (RPi)
sudo apt update
sudo apt install -y python3-pip python3-opencv libatlas-base-dev
```

### Setup

```bash
# Clone repository
git clone https://github.com/team/roadanon1.git
cd roadanon1

# Create virtual environment
python3 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# NCNN (build from source on RPi for ARM NEON support)
# See docs/ncnn_install.md for detailed instructions
```

### Model Files

Place model files in `models/`:

```
models/
â”œâ”€â”€ best.param          # YOLOv26n NCNN parameter file
â”œâ”€â”€ best.bin            # YOLOv26n NCNN weights
â””â”€â”€ autoencoder_fp16.onnx  # Autoencoder ONNX (FP16)
```

---

## Quick Start

### Run Pipeline (Headless)

```bash
# Process video files
python pipeline.py --sources test_video/*.mp4 --profile

# RPi optimized preset
python pipeline.py --rpi --sources test_video/*.mp4 --profile

# Live camera
python pipeline.py --rpi --sources 0 --profile
```

### Run GUI

```bash
python main.py
```

### Run Benchmark

```bash
# Quick 1-minute test
python benchmark.py --duration 60

# Full 10-minute stress test
python benchmark.py --rpi --duration 600
```

---

## GUI Application

The Tkinter-based GUI provides real-time visualization:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ ğŸ›£  Road Anomaly Detection                        â— RUNNING     â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                   â”‚  Mode                       â”‚
â”‚                                   â”‚  â—‹ Pi Camera / Webcam       â”‚
â”‚     Live Video Feed               â”‚  â— Video File               â”‚
â”‚     (with detection boxes)        â”‚  [path/to/video.mp4] [...]  â”‚
â”‚                                   â”‚                             â”‚
â”‚                                   â”‚  [â–¶ Start]  [â–  Stop]        â”‚
â”‚                                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤  Pipeline Stats             â”‚
â”‚  Autoencoder Processing           â”‚  FPS        12.4            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  Latency    81 ms           â”‚
â”‚  â”‚ Input  â”‚â”‚ Recon  â”‚â”‚Heatmap â”‚  â”‚  Motion %   8.3%            â”‚
â”‚  â”‚ (ROI)  â”‚â”‚        â”‚â”‚  (JET) â”‚  â”‚  AE Error   0.0721          â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜â””â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚  Anomaly    âš  YES           â”‚
â”‚  error: 0.0721 âš  ANOMALY        â”‚  YOLO       BUSY (23)       â”‚
â”‚                                   â”‚  Tracks     3               â”‚
â”‚                                   â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                   â”‚  âš  Anomaly Alerts           â”‚
â”‚                                   â”‚  [22:45:10] road_damage 87% â”‚
â”‚                                   â”‚  [22:45:08] speed_bump 72%  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Features

- **Dual mode**: Pi Camera (live) or video file playback
- **AE visualization**: Input â†’ Reconstruction â†’ Error Heatmap
- **Live stats**: FPS, latency (color-coded), motion %, AE error bar with threshold
- **YOLO status**: READY / BUSY / COOLDOWN with call count
- **Anomaly alerts**: Timestamped scrollable log

---

## Pipeline Modes

### Headless (`pipeline.py`)

For deployment on RPi without display. Outputs CSV, JSONL, and optional video.

```bash
python pipeline.py --rpi --sources video.mp4 --ae --profile --save-video
```

### GUI (`main.py`)

Interactive testing with live visualization. Runs on both desktop and RPi with display.

```bash
python main.py
```

### Benchmark (`benchmark.py`)

Hardware stress test with system monitoring.

```bash
python benchmark.py --rpi --duration 600
```

---

## Benchmarks

### 10-Minute Stress Test on RPi 4B

| Metric | Average | Peak | Status |
|--------|---------|------|--------|
| CPU (total) | 60.7% | 69.9% | âœ… < 80% |
| CPU (max core) | 79.2% | 99.0% | â€” |
| Temperature | 38.3Â°C | 40.4Â°C | âœ… < 70Â°C |
| Process RAM | 388.7 MB | 391.5 MB | âœ… < 500 MB |
| System RAM | 20.9% | 21.0% | âœ… |
| Threads | 22 | 22 | â€” |

### Thermal Stability

```
Temperature over 10 minutes (264 samples):
  Mean:   38.3Â°C
  Max:    40.4Â°C
  StdDev: Â±0.6Â°C
  â†’ No thermal throttling observed
  â†’ Heatsink + fan keeps temp within 4Â°C of ambient
```

### Optimization Impact

| Configuration | FPS | Latency |
|--------------|-----|---------|
| Baseline (sync YOLO, full frame) | ~1-2 | >500 ms |
| + Async YOLO | ~5-8 | ~200 ms |
| + ROI crop + frame skip | ~10-15 | ~100 ms |
| + AE pre-filter | ~12-18 | ~80 ms |
| + Motion weighting + backpressure | ~15-20 | ~60 ms |

---

## Optimization Techniques

### Pipeline Level

```mermaid
graph LR
    subgraph Optimizations
        A["Frame Skip\n3Ã— speedup"] --> B["ROI Crop\n2Ã— speedup"]
        B --> C["AE Throttle\n2Ã— speedup"]
        C --> D["Async YOLO\n2.5Ã— speedup"]
        D --> E["Backpressure\nStability"]
        E --> F["YOLO Cooldown\n-60% calls"]
    end

    style A fill:#2d5a2d,color:#fff
    style B fill:#2d5a2d,color:#fff
    style C fill:#2d5a2d,color:#fff
    style D fill:#2d5a2d,color:#fff
    style E fill:#2d5a2d,color:#fff
    style F fill:#2d5a2d,color:#fff
```

| Technique | Description | Impact |
|-----------|-------------|--------|
| **Async YOLO** | Non-blocking inference on background thread | 2.5Ã— FPS |
| **Frame skipping** | Process every 3rd raw frame | 3Ã— throughput |
| **AE throttling** | Run AE every 3rd processed frame | 2Ã— FPS |
| **YOLO cooldown** | Min 5 frames between submissions | -60% YOLO calls |
| **Motion weighting** | Soft threshold scaling (not binary skip) | +5% accuracy |
| **Backpressure** | Auto-skip AE when load > 1.5Ã— budget | Thermal stability |
| **ROI cropping** | Process only bottom 50% of frame | 2Ã— FPS |
| **Threaded I/O** | Camera capture on separate thread | +15% FPS |

### Model Level

| Technique | Description |
|-----------|-------------|
| **FP16 quantization** | AE model FP32 â†’ FP16 (50% smaller) |
| **NCNN backend** | ARM NEON SIMD vectorization for YOLO |
| **Auto dtype detection** | Reads model input type from ONNX metadata |
| **Letterbox preprocessing** | Aspect-ratio-preserving resize |

---

## Project Structure

```
roadanon1/
â”œâ”€â”€ ğŸ“„ main.py                  # Tkinter GUI application
â”œâ”€â”€ ğŸ“„ pipeline.py              # Headless pipeline orchestration
â”œâ”€â”€ ğŸ“„ benchmark.py             # Hardware utilization stress test
â”œâ”€â”€ ğŸ“„ config.py                # Centralized configuration + RPi preset
â”‚
â”œâ”€â”€ ğŸ§  Models & Inference
â”‚   â”œâ”€â”€ classifier_ncnn.py      # YOLOv26n NCNN with async thread
â”‚   â”œâ”€â”€ classifier.py           # YOLO wrapper (ONNX fallback)
â”‚   â”œâ”€â”€ autoencoder_tflite.py   # AE ONNX FP16 with temporal smoothing
â”‚   â”œâ”€â”€ autoencoder.py          # AE training script
â”‚   â””â”€â”€ convert_ae_tflite.py    # PyTorch â†’ ONNX FP16 converter
â”‚
â”œâ”€â”€ ğŸ”§ Pipeline Components
â”‚   â”œâ”€â”€ preprocessing.py        # Threaded camera capture
â”‚   â”œâ”€â”€ motion_detect.py        # Fast frame-differencing detector
â”‚   â”œâ”€â”€ tracker.py              # IoU-based multi-object tracker
â”‚   â””â”€â”€ cropping.py             # Frame cropping utilities
â”‚
â”œâ”€â”€ ğŸ“ models/                  # Model weights (gitignored)
â”‚   â”œâ”€â”€ best.param              # NCNN parameter file
â”‚   â”œâ”€â”€ best.bin                # NCNN weights
â”‚   â””â”€â”€ autoencoder_fp16.onnx   # AE ONNX model
â”‚
â”œâ”€â”€ ğŸ“ test_video/              # Test dashcam videos
â”œâ”€â”€ ğŸ“ output/                  # Detection outputs
â”œâ”€â”€ ğŸ“ report/                  # LaTeX project report
â”‚   â””â”€â”€ main.tex
â”œâ”€â”€ ğŸ“ docs/                    # Documentation
â”‚
â”œâ”€â”€ ğŸ“„ requirements.txt         # Python dependencies
â”œâ”€â”€ ğŸ“„ test_pipeline.py         # Pipeline tests
â””â”€â”€ ğŸ“„ README.md                # This file
```

---

## Configuration

### Default Configuration

```python
from config import Config

cfg = Config()
cfg.proc_width = 640          # Processing resolution
cfg.proc_height = 480
cfg.roi_top = 0.5             # Bottom 50% of frame
cfg.ae_enabled = True
cfg.ae_threshold = 0.06       # AE anomaly threshold
cfg.ae_smooth_window = 5      # Temporal smoothing window
cfg.ae_smooth_min_hits = 2    # Min anomalous frames in window
cfg.yolo_conf = 0.25          # YOLO confidence threshold
cfg.tracker_iou = 0.25        # Tracker IoU threshold
cfg.tracker_max_lost = 15     # Max frames before dropping track
```

### RPi Optimized Preset

```python
cfg = Config.rpi_preset()
# proc_width = 320, proc_height = 240
# skip_frames = 2
# ae_input_size = 64 (overridden to 128 by model)
# show_preview = False, save_video = False
```

---

## Output Formats

### Per-Frame CSV (`output/frames.csv`)

```csv
timestamp,frame,motion_pct,ae_error,anomaly,yolo_triggered,label,confidence,latency_ms
2026-02-20T22:45:10.123,240,8.3,0.0721,true,true,road_damage,0.87,81.2
2026-02-20T22:45:10.156,243,2.1,0.0412,false,false,,,12.3
```

### Detection JSONL (`output/detections.jsonl`)

```json
{"timestamp":"2026-02-20T22:45:10","track_id":7,"class":"road_damage","confidence":0.87,"bbox":{"x":120,"y":45,"w":80,"h":60},"ae_error":0.0721}
```

### Benchmark CSV (`output/benchmark.csv`)

```csv
elapsed_s,timestamp,cpu_total_pct,cpu_max_core_pct,ram_used_mb,ram_pct,proc_ram_mb,proc_threads,cpu_temp_c
0.0,2026-02-20T23:28:42,0.0,0.0,493,13.0,53.3,8,37.5
3.3,2026-02-20T23:28:46,62.3,80.8,792,20.9,335.6,22,36.5
```

---

## Team

| Name | Role |
|------|------|
| **Sunny Sharma** | Team Member |
| **Muskan Teckchandani** | Team Member |
| **Radhe Raman Sarkar** | Team Member |

**Institution**: World College of Technology and Management

**Challenge**: IIT Madras â€” Bharat AI System-on-Chip Challenge

---

## License

This project was developed as part of the IIT Madras Bharat AI SoC Challenge.

---

<p align="center">
  <i>Built for the edge. Optimized for the road.</i>
</p>
